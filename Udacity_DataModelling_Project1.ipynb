{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/home\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artist', 'firstName', 'gender', 'itemInSession', 'lastName', 'length', 'level', 'location', 'sessionId', 'song', 'userId']\n",
      "['Muse', 'Harper', 'M', '1', 'Barrett', '209.50159', 'paid', 'New York-Newark-Jersey City, NY-NJ-PA', '275', 'Supermassive Black Hole (Twilight Soundtrack Version)', '42']\n"
     ]
    }
   ],
   "source": [
    "#Printing first two rows, just to get columns name and to see data as well\n",
    "file_path1 = 'event_datafile_new.csv'\n",
    "\n",
    "# Open the CSV file\n",
    "with open(file_path1, mode='r') as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader1 = csv.reader(file)\n",
    "    \n",
    "    # Read and print the first two rows\n",
    "    for i, row in enumerate(csv_reader1):\n",
    "        print(row)\n",
    "        if i == 1:  # Stop after the second row\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist            object\n",
      "firstName         object\n",
      "gender            object\n",
      "itemInSession      int64\n",
      "lastName          object\n",
      "length           float64\n",
      "level             object\n",
      "location          object\n",
      "sessionId          int64\n",
      "song              object\n",
      "userId             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into a DataFrame\n",
    "df = pd.read_csv('event_datafile_new.csv')\n",
    "\n",
    "# Check the data types of each column\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. \n",
    "\n",
    "## The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity\n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "  \n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "## Query 1 - Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Description\n",
    " \n",
    " 1. Expected Output: We require to get artist name, song title and song length based upon sessionId=338 and itemInSession=4. So the following SQL is required to get this result.\n",
    " \n",
    " \"SELECT artist, song, length from music_library_by_sessionid_and_itemInSession WHERE sessionId = '338' AND itemInSession='4'\"\n",
    "         \n",
    "          \n",
    "          \n",
    " 2. Selecting of columns- We need to have the following columns\n",
    " sessionId , itemInSession , artist , song , length.\n",
    " \n",
    " 3. Choice of Primary Keys: We should choose sessionID partition key as for each session id Item in session is unique. We can choose item in session  as clustering key. \n",
    " Note- We can also choose the session id as clustering and Item in session as partition, this will not affect out result.\n",
    " \n",
    " 4. Need to create a table and insert rows from above csv file: We will create table using SQL create if not existed to avoid any errors. the name of the table would be music_library_by_sessionid_and_itemInSession. \n",
    " NOTE- We will make sure the order of create and insert would be same. In this case, make sure we have sessionId and itemInSession would be the first two column in this sequence only in create and insert columns, otherwise result would be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a table name music_library_by_itemInSession\n",
    "query = \"CREATE TABLE IF NOT EXISTS music_library_by_sessionid_and_itemInSession\"\n",
    "query = query + \"\"\"(sessionId int, itemInSession int, artist varchar, song varchar, length varchar,\n",
    "primary key(sessionId, itemInSession))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data from file = 'event_datafile_new.csv' and using for loop putting all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO music_library_by_sessionid_and_itemInSession(sessionId,itemInSession, artist, song, length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], line[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless | Music Matters (Mark Knight Dub) | 495.3073\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT artist, song, length from music_library_by_sessionid_and_itemInSession\n",
    "        WHERE sessionId =338 AND itemInSession=4 \"\"\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.artist,\"|\", row.song,\"|\", row.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY 2 - Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Description\n",
    " \n",
    " 1. Expected Output: We require to get artist name, song title and song length based upon userId=10 and sessionId=182, sorted by itemInSession. So the following SQL is required to get this result.\n",
    " \n",
    " \"SELECT artist, song, firstname, lastname from music_library_userid_sessionid\n",
    "WHERE userid='10' AND  sessionid = '182'\"\n",
    "        \n",
    "         \n",
    " 2. Selecting of columns- We need to have the following columns\n",
    " userid, sessionid, itemInSession, artist, song, firstName, lastName\n",
    " \n",
    " 3. Choice of Primary Keys: We should choose userid as partition key. For first clustering column it has to be sessionId to as we need to filter data accordint to it and this will  make our key unique as well. The second clustering column would be itemInSession as we have to sort our results based upon it.\n",
    " \n",
    " \n",
    " \n",
    " 4. Need to create a table and insert rows from above csv file: We will create table using SQL create if not existed to avoid any errors. the name of the table would be music_library_userid_sessionid. \n",
    " NOTE- We will make sure the order of create and insert would be same. In this case, make sure we have userid, sessionid and iteminSession  would be the first three columns in this sequence only in create and insert columns, otherwise result would be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a table name music_library_userid_sessionid\n",
    "query = \"CREATE TABLE IF NOT EXISTS music_library_userid_sessionid \"\n",
    "query = query + \"\"\"(userid int, sessionid int, itemInSession int, artist varchar, song varchar,\n",
    "firstName varchar, lastName varchar, primary key(userid,sessionid,itemInSession))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data from file = 'event_datafile_new.csv' and using for loop putting all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) \n",
    "    for line in csvreader:\n",
    "        query = \"\"\"INSERT INTO music_library_userid_sessionid (userid, sessionid, itemInSession,  \n",
    "        artist, song, firstName, lastName)\"\"\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone | Keep On Keepin' On | Sylvie | Cruz\n",
      "Three Drives | Greece 2000 | Sylvie | Cruz\n",
      "Sebastien Tellier | Kilometer | Sylvie | Cruz\n",
      "Lonnie Gordon | Catch You Baby (Steve Pitron & Max Sanna Radio Edit) | Sylvie | Cruz\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT iteminsession, artist, song, firstname, lastname from music_library_userid_sessionid\n",
    "WHERE userid=10 AND  sessionid =182 \"\"\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row.artist, \"|\", row.song, \"|\", row.firstname, \"|\", row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY 3 - Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Description\n",
    " \n",
    " 1. Expected Output: We need to get first and last name of each users who are istening to one title song \"All Hands Against His Own\". So for sure we need to make query like this:\n",
    " \"SELECT firstname, lastname from music_library_songtitle WHERE song='All Hands Against His Own'\"\n",
    " \n",
    " 2. Selecting of columns- We need to have the following columns\n",
    "song, userid, firstName, lastName\n",
    " \n",
    " 2. Choice of Primary Keys: For partition key we will definalty go with Song name. Now this is possible that there are many people with same first and last name and listening to same song. So we will add userid to clustering columns to make our primary key unique.\n",
    " \n",
    " 3. Need to create a table:We will create table using SQL create if not existed to avoid any errors. the name of the table would be music_library_songtitle.\n",
    " NOTE- We will make sure the order of create and insert would be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS music_library_songtitle \"\n",
    "query = query + \"\"\"(song varchar, userid int,firstName varchar, lastName varchar,\n",
    "primary key(song, userid))\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO music_library_songtitle(song, userid, firstName, lastName)\"\n",
    "        query = query + \" VALUES ( %s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline | Lynch\n",
      "Tegan | Levine\n",
      "Sara | Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT firstname, lastname from music_library_songtitle WHERE song='All Hands Against His Own'  \"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.firstname,\"|\", row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"drop table music_library_by_sessionid_and_itemInSession\"\n",
    "try:\n",
    "    rows1 = session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query2 = \"drop table music_library_userid_sessionid\"\n",
    "try:\n",
    "    rows2 = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query3 = \"drop table music_library_songtitle\"\n",
    "try:\n",
    "    rows3 = session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
